---
title: "Slicr and DiceR Project 1"
author: "Spencer Abbot, Chi Cheung, Eric Goldman"
date: "10/4/2017"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = TRUE)

#Set Working Directory
#setwd("/Users/Spencer/Project_1")
setwd("/Users/ericg/Desktop/DATS 6101/GITHUB/Project_1")
#setwd("/Users/Chidog/Project_1")
```

```{r install, eval=TRUE}
#install packages for the project
install.packages("maps", repos="http://cran.rstudio.com/")
install.packages("ggplot2", repos="http://cran.rstudio.com/")
install.packages("pastecs", repos="http://cran.rstudio.com/")

```

```{r US MAP PLOT, eval=TRUE}
#Plotting Map of the US and the fifty metro cities analyzed
#Call library for maps and plotting already installed 
library(ggplot2)
library(maps)

#US map - data
all_states <- map_data("state")

#Read in Lat Long Data from City
citylatlong <- data.frame(read.csv("citylatlong.csv"))

#Plot US states using ggplot2
p <- ggplot()
p <- p + geom_polygon( data=all_states, 
aes(x=long, y=lat, group = group),colour="white", fill="grey10" )
p;

#Plot data points (lat/long of MSA's) to US map
p + geom_point(data=citylatlong, 
aes(y=LAT, x=LONG, color=Population, size=Population)) +
  ggtitle("US Metro Statistical Areas with Population over 1 million")+
    theme_bw() +
  theme( plot.title=element_text(hjust=0.5),
         axis.line = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.text.y =element_blank(),
    axis.text.x=element_blank(),
    axis.ticks.y=element_blank(),
    axis.ticks.x=element_blank()) +
    xlab("") + 
    ylab("")
```

```{r citystats}
#Read in CityData csv and call stats package
library(stats)
citydata <- data.frame(read.csv("CityData.csv"))

#CityData Exploration - 50 obs of 9 variables
head(citydata)
str(citydata)
summary(citydata)

#Gather stats for citydata
library(pastecs)
stat.desc(citydata)

#Testing for normality
hist(citydata$Amazon_HQIndex)
shapiro.test(citydata$Amazon_HQIndex)


```
P-value is 0.084. Fail to reject normality but there appears to be an outlier.
Will explore outlier city (Memphis) later in Rmarkdown

```{r anova}
#Comparing MLB Team on Amazon HQ Index
boxplot(citydata$Amazon_HQIndex~citydata$MLB_Team)
#Appears to be even, using ANOVA to investigate

model.degree <- aov(Amazon_HQIndex~MLB_Team, data = citydata)
hist(model.degree$residuals, main = "Hist of Res", xlab = "Residuals")
summary(model.degree)
TukeyHSD(model.degree)
x <- lm(Amazon_HQIndex~MLB_Team, data = citydata)
summary(x)
#P-value of .318, fail to reject the means are equal. 


#CityData Correlation Exploration
plot(citydata)
plot(Amazon_HQIndex ~ F500_HQ, data=citydata)
plot(citydata$Amazon_HQIndex, citydata$CrimeIndex)
cor(citydata$ZillowHVI,citydata$CollegeDegree, method="pearson")
cor(citydata$Amazon_HQIndex,citydata$Population, method="pearson")
cor(citydata[,2:8], method="pearson")
qqnorm(citydata[,8], main="Amazon Index Score Q-Q Plot")
qqline (citydata[,8], col=2)
```

The last city, Memphis is an outlier among the Amazon HQ Index.
Will test for the outlier and remove the obs.
Then will test the normality again which will yield a higher p-value

```{r, eval=TRUE}
#Outlier Function
attach(citydata)
citydata.sort <- citydata[order(Amazon_HQIndex, decreasing = TRUE),]
detach(citydata)
outlierKD <- function(dt, var) {
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     par(mfrow=c(2, 2), oma=c(0,0,3,0))
     boxplot(var_name, main="With outliers")
     hist(var_name, main="With outliers", xlab=NA, ylab=NA)
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     boxplot(var_name, main="Without outliers")
     hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
     title("Outlier Check", outer=TRUE)
     na2 <- sum(is.na(var_name))
     cat("Outliers identified:", na2 - na1, "n")
     cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
     cat("Mean of the outliers:", round(mo, 2), "n")
     m2 <- mean(var_name, na.rm = T)
     cat("Mean without removing outliers:", round(m1, 2), "n")
     cat("Mean if we remove outliers:", round(m2, 2), "n")
     response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
     if(response == "y" | response == "yes"){
          dt[as.character(substitute(var))] <- invisible(var_name)
          assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
          cat("Outliers successfully removed", "n")
          return(invisible(dt))
     } else{
          cat("Nothing changed", "n")
          return(invisible(var_name))
     }
}
#test for outlier but will say NO to remove as we will remove it on the next line of code
outlierKD(citydata.sort, Amazon_HQIndex)

#Remove Memphis
citydata.sort.remove_Memphis <-citydata.sort[-c(50),]
hist(citydata.sort.remove_Memphis$Amazon_HQIndex)
shapiro.test(citydata.sort.remove_Memphis$Amazon_HQIndex)
#p value of 0.5349. Much different than the earlier .0841

model.degree.sort <- aov(Amazon_HQIndex~MLB_Team, data = citydata.sort.remove_Memphis)
hist(model.degree.sort$residuals, main = "Hist of Res", xlab = "Residuals")
summary(model.degree.sort)
TukeyHSD(model.degree.sort)
qqnorm(citydata.sort.remove_Memphis[,8], main="Amazon Index Score w/o Outlier Q-Q Plot")
qqline (citydata.sort.remove_Memphis[,8], col=2)


#Removing Memphis 

```
